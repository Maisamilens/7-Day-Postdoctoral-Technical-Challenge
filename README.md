# ğŸ« 7-Day Postdoctoral Technical Challenge
### AI Medical Imaging Â· Visual Language Models Â· Semantic Retrieval

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?style=flat-square&logo=python" />
  <img src="https://img.shields.io/badge/PyTorch-2.0-EE4C2C?style=flat-square&logo=pytorch" />
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-FFD21E?style=flat-square&logo=huggingface" />
  <img src="https://img.shields.io/badge/FAISS-Vector%20Search-009EFF?style=flat-square" />
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" />
</p>

> **Institution:** AlfaisalX Â· Cognitive Robotics and Autonomous Agents  
> **Unit:** MedX Research Unit, Medical Robotics & AI in Healthcare  
> **College:** Engineering and Advanced Computing, Alfaisal University, Riyadh  
> **Deadline:** February 22, 2026

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Dataset](#-dataset)
- [Repository Structure](#-repository-structure)
- [Task 1 â€” CNN Classification](#-task-1--cnn-classification)
- [Task 2 â€” Medical Report Generation](#-task-2--medical-report-generation)
- [Task 3 â€” Semantic Image Retrieval](#-task-3--semantic-image-retrieval)
- [Quick Start](#-quick-start)
- [Results Summary](#-results-summary)
- [Environment Setup](#-environment-setup)

---

## ğŸ” Overview

This repository is a complete end-to-end AI pipeline for chest X-ray analysis combining three interconnected components:

| # | Task | Technology | Purpose |
|---|------|-----------|---------|
| 1 | **CNN Classification** | EfficientNet-B3 (Transfer Learning) | Pneumonia vs Normal detection |
| 2 | **Report Generation** | BLIP-2 / MedGemma (VLM) | Automated radiology report writing |
| 3 | **Image Retrieval** | CLIP + FAISS | Content-based similar-case search |

Built on the **Chest X-Ray Pneumonia** dataset (Kaggle), this system demonstrates how deep learning, large language models, and vector search can be combined into a clinical decision support prototype.

---

## ğŸ“‚ Dataset

**Source:** [Chest X-Ray Images (Pneumonia) â€” Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)

```
chest_xray/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ NORMAL/       1,341 images
â”‚   â””â”€â”€ PNEUMONIA/    3,875 images
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ NORMAL/       8 images
â”‚   â””â”€â”€ PNEUMONIA/    8 images
â””â”€â”€ test/
    â”œâ”€â”€ NORMAL/       234 images
    â””â”€â”€ PNEUMONIA/    390 images
```

| Split | NORMAL | PNEUMONIA | Total |
|-------|--------|-----------|-------|
| Train | 1,341  | 3,875     | 5,216 |
| Val   | 8      | 8         | 16    |
| Test  | 234    | 390       | 624   |

> âš ï¸ **Class imbalance:** ~2.9:1 (PNEUMONIA:NORMAL) â€” handled via `WeightedRandomSampler`

---

## ğŸ“ Repository Structure

```
7-Day-Postdoctoral-Technical-Challenge/
â”‚
â”œâ”€â”€ task1_classification/
â”‚   â””â”€â”€ task1_classification.py          # EfficientNet-B3 full pipeline
â”‚
â”œâ”€â”€ task2_report_generation/
â”‚   â””â”€â”€ task2_report_generation.py       # BLIP-2 / MedGemma VLM pipeline
â”‚
â”œâ”€â”€ task3_retrieval/
â”‚   â””â”€â”€ task3_retrieval.py               # CLIP + FAISS retrieval system
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ medical_imaging_challenge.ipynb  # Master Kaggle notebook (all 3 tasks)
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ task1_classification_report.md
â”‚   â”œâ”€â”€ task2_report_generation.md
â”‚   â””â”€â”€ task3_retrieval_system.md
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Task 1 â€” CNN Classification

**Objective:** Train a CNN to classify chest X-rays as Normal or Pneumonia, with thorough evaluation and failure case analysis.

### Model Architecture

```
EfficientNet-B3  (ImageNet pretrained)
â”‚
â”œâ”€â”€ Backbone â”€â”€â”€â”€ Frozen (except features.7 & features.8)
â”‚
â””â”€â”€ Classifier Head (trainable):
      Dropout(0.4)
   â†’  Linear(1536 â†’ 256)
   â†’  SiLU
   â†’  Dropout(0.2)
   â†’  Linear(256 â†’ 2)
```

**Why EfficientNet-B3?**  
Compound scaling of width, depth, and resolution achieves better accuracy per FLOP than ResNet at this scale. MBConv blocks with Squeeze-and-Excitation attention are well-suited for localising subtle radiological features. Pretrained ImageNet weights transfer low-level edge/texture detectors to the X-ray domain.

### Training Hyperparameters

| Parameter | Value |
|-----------|-------|
| Image size | 224 Ã— 224 |
| Batch size | 32 |
| Epochs | 25 |
| Optimizer | AdamW |
| Learning rate | 1e-4 |
| Weight decay | 1e-5 |
| LR scheduler | CosineAnnealingLR |
| Mixed precision | FP16 (`torch.cuda.amp`) |
| Imbalance strategy | `WeightedRandomSampler` |

### Augmentation

```
Resize(256) â†’ RandomCrop(224) â†’ RandomHorizontalFlip
â†’ RandomRotation(Â±10Â°) â†’ ColorJitter â†’ RandomAffine
â†’ Normalize (ImageNet Î¼/Ïƒ)
```

### Outputs

```
task1_outputs/
â”œâ”€â”€ training_curves.png        â€” Loss, Accuracy, AUC, F1, Precision/Recall
â”œâ”€â”€ confusion_matrix.png       â€” Raw + normalized confusion matrices
â”œâ”€â”€ roc_curve.png              â€” ROC with Youden's J optimal threshold
â”œâ”€â”€ sample_predictions.png     â€” 16 random test predictions
â”œâ”€â”€ failure_cases.png          â€” Misclassified images with confidence
â””â”€â”€ task1_classification_report.md

models/
â””â”€â”€ best_efficientnet_b3.pth   â€” Best checkpoint (saved by Val AUC)
```

### Run

```bash
python task1_classification/Task_1_code.py
```

---

## ğŸ“ Task 2 â€” Medical Report Generation

**Objective:** Use a Visual Language Model (VLM) to automatically generate natural language radiology reports from chest X-ray images.

### Model Options

| Model | Default? | Notes |
|-------|----------|-------|
| **BLIP-2 OPT-2.7B** | âœ… Yes | No auth required, free GPU tier |
| **MedGemma-4B-IT** | â­ Preferred | Medical-domain trained, needs HF token |

MedGemma is recommended for production as it is pre-trained on radiology data and produces more accurate clinical terminology. To enable it:

```bash
# 1. Accept license: https://huggingface.co/google/medgemma-4b-it
# 2. Set environment variable â€” NEVER commit tokens to Git
export HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxxxxx
# In Kaggle: Notebook Settings â†’ Secrets â†’ Add Secret â†’ Key: HUGGINGFACE_TOKEN
```

### Prompting Strategies Tested

| Strategy | Description | Use Case |
|----------|-------------|----------|
| `basic` | "Describe the findings in this chest X-ray." | Baseline |
| `clinical_structured` | Lung Fields â†’ Cardiac â†’ Pleural â†’ Impression | Best clinical output |
| `differential` | Radiological features + differential diagnosis | Ambiguous cases |
| `clinical_brief` | Binary verdict + key finding, concise | Triage |

### Pipeline

```
Chest X-Ray (upscaled to 512Ã—512 if small)
      â”‚
      â–¼
   VLM Encoder + Structured Prompt
      â”‚
      â–¼
   Generated Report Text
      â”‚
      â–¼
   Keyword Alignment Scoring vs Ground Truth
```

### Outputs

```
task2_outputs/
â”œâ”€â”€ report_cards.png           â€” Image + report side-by-side (6 cards)
â”œâ”€â”€ prompt_comparison.png      â€” 4 strategies compared on same image
â”œâ”€â”€ all_reports.csv            â€” 40 reports (10 images Ã— 4 prompts)
â””â”€â”€ task2_report_generation.md
```

### Run

```bash
python task2_report_generation/Task_2_code.py
```

---

## ğŸ” Task 3 â€” Semantic Image Retrieval

**Objective:** Build a Content-Based Image Retrieval (CBIR) system so clinicians can find visually similar X-ray cases from a database.

### System Architecture

```
Query: Image  â”€â”€â”
Query: Text   â”€â”€â”´â”€â”€â–¶  CLIP / BiomedCLIP Encoder
                           â”‚  512-dim L2-normalized vector
                           â–¼
                     FAISS IndexFlatIP
                           â”‚  cosine similarity search
                           â–¼
                      Top-k Results
                 (path Â· label Â· similarity score)
```

### Embedding Model Comparison

| Model | Dim | Text Search | Medical Domain |
|-------|-----|-------------|----------------|
| **CLIP ViT-B/32** *(default)* | 512 | âœ… | âŒ General |
| **BiomedCLIP** *(preferred)* | 512 | âœ… | âœ… 15M PubMed pairs |

### CLI Usage

```bash
# Build index + full evaluation
python task3_retrieval/Task_3_code.py --mode full

# Image-to-image search
python task3_retrieval/task3_retrieval.py \
    --mode search_image \
    --query /path/to/xray.jpeg \
    --k 5

# Text-to-image search
python task3_retrieval/task3_retrieval.py \
    --mode search_text \
    --query "bilateral consolidation with air bronchograms" \
    --k 5
```

### Evaluation â€” Precision@k

> **P@k** = (# top-k results sharing query label) / k  
> Random binary baseline = **0.500**  
> Values above 0.5 confirm embeddings meaningfully cluster similar pathology.

### Outputs

```
task3_outputs/
â”œâ”€â”€ retrieval_results.png      â€” Query | Top-5 grid (green=match, red=mismatch)
â”œâ”€â”€ text_retrieval_results.png â€” Clinical text queries â†’ retrieved images
â”œâ”€â”€ precision_at_k.png         â€” P@{1,3,5,10} bar chart vs baseline
â”œâ”€â”€ tsne_embeddings.png        â€” t-SNE 2D of CLIP embedding space
â””â”€â”€ task3_retrieval_system.md

task3_outputs/index/
â”œâ”€â”€ test_embeddings.npy        â€” 624 Ã— 512 float32 embedding matrix
â”œâ”€â”€ test_metadata.json         â€” Image paths and labels
â””â”€â”€ test_index.faiss           â€” FAISS IndexFlatIP
```

---

## ğŸš€ Quick Start

### Option A â€” Kaggle (Recommended)

```
1. Create a new Kaggle notebook
2. Add dataset: chest-xray-pneumonia
3. Upload: notebooks/medical_imaging_challenge.ipynb
4. Accelerator: GPU T4 x2
5. Run All
```

### Option B â€” Local

```bash
# Clone
git clone https://github.com/Maisamilens/7-Day-Postdoctoral-Technical-Challenge.git
cd 7-Day-Postdoctoral-Technical-Challenge

# Install
pip install -r requirements.txt

# Update DATA_ROOT in each script to your local dataset path, then:
python task1_classification/task1_classification.py
python task2_report_generation/task2_report_generation.py
python task3_retrieval/task3_retrieval.py --mode full
```

---

## ğŸ“Š Results Summary

### Task 1 â€” Test Set Performance (EfficientNet-B3)

| Metric | Score |
|--------|-------|
| Accuracy | ~93% |
| Precision | ~93% |
| **Recall (Sensitivity)** | **~96%** |
| Specificity | ~88% |
| F1-Score | ~94% |
| **AUC-ROC** | **~97%** |

> Recall is the most clinically critical metric â€” a missed pneumonia (false negative) is more dangerous than a false positive.

### Task 3 â€” Retrieval Precision@k (CLIP ViT-B/32)

| k | P@k | vs Baseline |
|---|-----|------------|
| 1 | ~0.78 | +0.28 |
| 3 | ~0.76 | +0.26 |
| 5 | ~0.75 | +0.25 |
| 10 | ~0.73 | +0.23 |

> Baseline (random binary retrieval) = 0.500

---

## âš™ï¸ Environment Setup

### requirements.txt

```
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.41.0
accelerate>=0.27.0
sentencepiece
faiss-cpu
open_clip_torch
scikit-learn>=1.3.0
seaborn>=0.13.0
matplotlib>=3.7.0
pandas>=2.0.0
numpy>=1.24.0
Pillow>=10.0.0
tqdm>=4.65.0
nbformat>=5.9.0
```

### Hardware Requirements

| Task | Minimum | Recommended |
|------|---------|-------------|
| Task 1 â€” Training | CPU (slow) | Kaggle T4 GPU |
| Task 2 â€” VLM Inference | T4 16GB | A100 (for MedGemma) |
| Task 3 â€” Embeddings + FAISS | CPU | T4 GPU |

---

## ğŸ”¬ Design Decisions

**Class Imbalance (2.9:1)** â€” Handled using `WeightedRandomSampler`. The minority class (NORMAL) is sampled with proportionally higher probability, avoiding image duplication which would cause overfitting.

**FAISS Index** â€” `IndexFlatIP` (exact cosine similarity on L2-normalized vectors) was chosen over approximate methods because the 624-vector test set is small enough for exact search without speed compromise.

**VLM Upscaling** â€” Images smaller than 256px are upscaled to 512Ã—512 (bicubic) before VLM inference to improve attention-layer feature extraction.

**Failure Cases** â€” Common misclassification patterns: (1) mild pneumonia with subtle consolidation resembles normal at 224Ã—224; (2) pulmonary edema occasionally misclassified as pneumonia; (3) non-standard projections deviate from standard PA-view training distribution.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

<p align="center">Built with PyTorch Â· HuggingFace Transformers Â· FAISS Â· OpenAI CLIP</p>
